version: "3"

services:
    
    elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:6.6.1
        environment:
            ES_JAVA_OPTS: '-Xms512m -Xmx512m'
        networks:
            - logging
        volumes:
            - elk_data:/usr/share/elasticsearch/data
        labels:
            com.docker.stack.namespace: "logging"
            com.docker.service.name: "elasticsearch"
        deploy:
            placement:
                constraints:
                # Hostname of the manager node!
                - node.hostname == m1
            mode: replicated
            update_config:
                parallelism: 1
                delay: 60s
            restart_policy:
                condition: none
                max_attempts: 5
            labels:
                com.docker.stack.namespace: "logging"
                com.docker.service.name: "elasticsearch"

    curator:
        image: robinong79/docker-elasticsearch-curator:v1.0
        networks:
            - logging
        environment:
            - ELASTICSEARCH_HOST=elasticsearch
            - ELASTICSEARCH_PORT=9200
            - INTERVAL_IN_HOURS=12
        volumes:
            - curator_data:/var/curator
        labels:
            com.docker.stack.namespace: "logging"
            com.docker.service.name: "curator"
        deploy:
            mode: replicated
            update_config:
                parallelism: 1
                delay: 60s
            restart_policy:
                condition: none
                max_attempts: 5
            labels:
                com.docker.stack.namespace: "logging"
                com.docker.service.name: "curator"                   

    logstash:
        image: docker.elastic.co/logstash/logstash:6.7.0
        depends_on:
            - elasticsearch
        ports:
            - "12201:12201/udp"         
            - "8080:8082"
        networks:
            - logging
        command: -e "input { gelf {} } output { elasticsearch { hosts => ['elasticsearch']} stdout {} }"
        labels:
            com.docker.stack.namespace: "logging"
            com.docker.service.name: "logstash"
        deploy:
            
            mode: replicated
            update_config:
                parallelism: 1
                delay: 60s
            restart_policy:
                condition: none
                max_attempts: 5
            labels:
                com.docker.stack.namespace: "logging"
                com.docker.service.name: "logstash"

    kibana:
        image: docker.elastic.co/kibana/kibana-oss:6.6.1
        depends_on:
            - elasticsearch                 
        networks:
            - logging
            - proxy
        environment:
            - ELASTICSEARCH_URL=http://elasticsearch:9200
        labels:
            com.docker.stack.namespace: "logging"
            com.docker.service.name: "kibana"
        deploy:
            mode: replicated
            update_config:
                parallelism: 1
                delay: 60s
            restart_policy:
                condition: none
                max_attempts: 5
            labels:
                com.docker.stack.namespace: "logging"
                com.docker.service.name: "kibana"    
                traefik.enable: "true"
                traefik.port: "5601"
                traefik.frontend.rule: "Host:logging.metabrokr.us"
                traefik.docker.network: "proxy"             

networks:
    logging:
        external: true
    proxy:
        external: true
volumes:
 elk_data:
  external: true
 curator_data:
  external: true