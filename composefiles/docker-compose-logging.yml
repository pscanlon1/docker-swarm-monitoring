version: "3"

services:
    
    elasticsearch:
        image: elasticsearch
        networks:
            - logging
        volumes:
            - ../dockerdata/elasticsearch/data:/usr/share/elasticsearch/data
        labels:
            com.docker.stack.namespace: "logging"
            com.docker.service.name: "elasticsearch"
        deploy:
            mode: replicated
            update_config:
                parallelism: 1
                delay: 60s
            restart_policy:
                condition: none
                max_attempts: 5
            labels:
                com.docker.stack.namespace: "logging"
                com.docker.service.name: "elasticsearch"

    curator:
        image: robinong79/docker-elasticsearch-curator:v1.0
        networks:
            - logging
        environment:
            - ELASTICSEARCH_HOST=elasticsearch
            - ELASTICSEARCH_PORT=9200
            - INTERVAL_IN_HOURS=12
        volumes:
            - ../dockerdata/curator:/var/curator
        labels:
            com.docker.stack.namespace: "logging"
            com.docker.service.name: "curator"
        deploy:
            mode: replicated
            update_config:
                parallelism: 1
                delay: 60s
            restart_policy:
                condition: none
                max_attempts: 5
            labels:
                com.docker.stack.namespace: "logging"
                com.docker.service.name: "curator"                   

    logstash:
        image: logstash:latest
        depends_on:
            - elasticsearch
        ports:
            - "12201:12201/udp"         
            - "8080:8082"
        networks:
            - logging
        command: -e "input { gelf {} } output { elasticsearch { hosts => ['elasticsearch']} stdout {} }"
        labels:
            com.docker.stack.namespace: "logging"
            com.docker.service.name: "logstash"
        deploy:
            mode: replicated
            update_config:
                parallelism: 1
                delay: 60s
            restart_policy:
                condition: none
                max_attempts: 5
            labels:
                com.docker.stack.namespace: "logging"
                com.docker.service.name: "logstash"

    kibana:
        image: kibana
        depends_on:
            - elasticsearch                 
        networks:
            - logging
            - proxy
        environment:
            - ELASTICSEARCH_URL=http://elasticsearch:9200
        labels:
            com.docker.stack.namespace: "logging"
            com.docker.service.name: "kibana"
        deploy:
            mode: replicated
            update_config:
                parallelism: 1
                delay: 60s
            restart_policy:
                condition: none
                max_attempts: 5
            labels:
                com.docker.stack.namespace: "logging"
                com.docker.service.name: "kibana"    
                traefik.enable: "true"
                traefik.port: "5601"
                traefik.frontend.rule: "Host:logging.metabrokr.us"
                traefik.docker.network: "proxy"             

networks:
    logging:
        external: true
    proxy:
        external: true

